# 实施任务清单

## 1. 游戏逻辑重构
- [ ] 1.1 将 `main.py` 中的游戏逻辑封装为 `WerewolfGame` 类
- [ ] 1.2 提取 Agent 创建逻辑为可配置的工厂函数
- [ ] 1.3 确保重构后原有 `python main.py` 运行方式不变
- [ ] 1.4 添加游戏结果返回接口（胜负、角色、存活信息等）

## 2. 评估框架实现
- [ ] 2.1 创建 `evaluation/` 目录结构
- [ ] 2.2 实现 `GameRunner` 类（批量运行游戏）
  - [ ] 2.2.1 支持配置游戏局数
  - [ ] 2.2.2 支持注入 Agent 工厂函数
  - [ ] 2.2.3 实现进度显示功能
  - [ ] 2.2.4 支持随机种子设置（可复现）
- [ ] 2.3 实现 `ResultRecorder` 类（记录游戏结果）
  - [ ] 2.3.1 定义游戏结果数据结构
  - [ ] 2.3.2 实现结果保存（JSON 格式）
  - [ ] 2.3.3 支持增量记录
- [ ] 2.4 实现 `StatisticsAnalyzer` 类（统计分析）
  - [ ] 2.4.1 计算总体胜率（好人 vs 狼人）
  - [ ] 2.4.2 计算特定 Agent 的胜率
  - [ ] 2.4.3 计算各角色的平均存活时间
  - [ ] 2.4.4 生成对比统计（基线 vs 自定义）
- [ ] 2.5 实现 `ReportGenerator` 类（报告生成）
  - [ ] 2.5.1 生成文本格式报告
  - [ ] 2.5.2 生成 JSON 格式报告
  - [ ] 2.5.3 包含关键指标可视化（表格形式）

## 3. 评估入口实现
- [ ] 3.1 创建 `evaluate.py` 脚本
- [ ] 3.2 实现命令行参数解析
  - [ ] 3.2.1 `--num-games`: 游戏局数（默认 10）
  - [ ] 3.2.2 `--custom-agent`: 自定义 Agent 模块路径
  - [ ] 3.2.3 `--output`: 输出报告路径
  - [ ] 3.2.4 `--seed`: 随机种子
- [ ] 3.3 实现基线 vs 自定义对比模式
- [ ] 3.4 实现日志和进度输出

## 4. 示例自定义 Agent
- [ ] 4.1 创建 `examples/agent_werewolves/` 目录
- [ ] 4.2 实现示例自定义 Agent（继承 ReActAgent）
- [ ] 4.3 添加使用文档和说明
- [ ] 4.4 确保符合比赛要求（observe、state_dict、结构化输出等）

## 5. 文档和测试
- [ ] 5.1 编写评估系统使用文档
- [ ] 5.2 添加使用示例和命令说明
- [ ] 5.3 测试单局游戏仍正常运行
- [ ] 5.4 测试批量评估功能
- [ ] 5.5 测试对比评估功能
- [ ] 5.6 验证结果数据的准确性

## 6. 优化和完善
- [ ] 6.1 添加异常处理（游戏运行失败时）
- [ ] 6.2 优化内存使用（避免大量局数时内存溢出）
- [ ] 6.3 添加配置文件支持（可选）
- [ ] 6.4 代码格式化 (`ruff format`)
- [ ] 6.5 类型标注检查 (`pyright`)

